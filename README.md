# Transformers from scratch

The implemented Transformer architecture is written from scratchÂ using PyTorch, described in ["Attention is all you need"](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf).

The Vision Transformer (ViT) model, described in ["An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"](https://arxiv.org/pdf/2010.11929), is extended from the base Transformer architecture implemented here.
